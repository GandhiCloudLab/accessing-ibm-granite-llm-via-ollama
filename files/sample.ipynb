{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9545b7ea-5f78-42d3-afae-90acfd5a6778",
   "metadata": {},
   "source": [
    "# Accessing IBM Granite LLM via Ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a92237-be19-4cd3-8a28-99895a3d0e94",
   "metadata": {},
   "source": [
    "This notebook helps to access the IBM Granite model using Ollama."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e017ef9-ce4b-4e47-9f1d-70d64b38c559",
   "metadata": {},
   "source": [
    "### Install langchain-ollama Module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5142d40f-2cab-4e8b-a9ed-42cdc351a506",
   "metadata": {},
   "source": [
    "Install the langchain-ollama module in the Python Kernal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "922b3f8e-2dcf-4974-8bb8-b44ee530178e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-ollama\n",
      "  Using cached langchain_ollama-0.2.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting langchain-core<0.4.0,>=0.3.0 (from langchain-ollama)\n",
      "  Using cached langchain_core-0.3.12-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting ollama<1,>=0.3.0 (from langchain-ollama)\n",
      "  Using cached ollama-0.3.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./my-jupyter-env/lib/python3.9/site-packages (from langchain-core<0.4.0,>=0.3.0->langchain-ollama) (6.0.2)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.0->langchain-ollama)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.125 (from langchain-core<0.4.0,>=0.3.0->langchain-ollama)\n",
      "  Using cached langsmith-0.1.137-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./my-jupyter-env/lib/python3.9/site-packages (from langchain-core<0.4.0,>=0.3.0->langchain-ollama) (24.1)\n",
      "Collecting pydantic<3.0.0,>=2.5.2 (from langchain-core<0.4.0,>=0.3.0->langchain-ollama)\n",
      "  Using cached pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<0.4.0,>=0.3.0->langchain-ollama)\n",
      "  Using cached tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./my-jupyter-env/lib/python3.9/site-packages (from langchain-core<0.4.0,>=0.3.0->langchain-ollama) (4.12.2)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in ./my-jupyter-env/lib/python3.9/site-packages (from ollama<1,>=0.3.0->langchain-ollama) (0.27.2)\n",
      "Requirement already satisfied: anyio in ./my-jupyter-env/lib/python3.9/site-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.3.0->langchain-ollama) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in ./my-jupyter-env/lib/python3.9/site-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.3.0->langchain-ollama) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in ./my-jupyter-env/lib/python3.9/site-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.3.0->langchain-ollama) (1.0.6)\n",
      "Requirement already satisfied: idna in ./my-jupyter-env/lib/python3.9/site-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.3.0->langchain-ollama) (3.10)\n",
      "Requirement already satisfied: sniffio in ./my-jupyter-env/lib/python3.9/site-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.3.0->langchain-ollama) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./my-jupyter-env/lib/python3.9/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama<1,>=0.3.0->langchain-ollama) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./my-jupyter-env/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain-ollama) (3.0.0)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.0->langchain-ollama)\n",
      "  Using cached orjson-3.10.10-cp39-cp39-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl.metadata (50 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in ./my-jupyter-env/lib/python3.9/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.0->langchain-ollama) (2.32.3)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.0->langchain-ollama)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.0->langchain-ollama)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.23.4 (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.0->langchain-ollama)\n",
      "  Using cached pydantic_core-2.23.4-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./my-jupyter-env/lib/python3.9/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.0->langchain-ollama) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./my-jupyter-env/lib/python3.9/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.0->langchain-ollama) (2.2.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in ./my-jupyter-env/lib/python3.9/site-packages (from anyio->httpx<0.28.0,>=0.27.0->ollama<1,>=0.3.0->langchain-ollama) (1.2.2)\n",
      "Using cached langchain_ollama-0.2.0-py3-none-any.whl (14 kB)\n",
      "Using cached langchain_core-0.3.12-py3-none-any.whl (407 kB)\n",
      "Using cached ollama-0.3.3-py3-none-any.whl (10 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached langsmith-0.1.137-py3-none-any.whl (296 kB)\n",
      "Using cached pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "Using cached pydantic_core-2.23.4-cp39-cp39-macosx_11_0_arm64.whl (1.7 MB)\n",
      "Using cached tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached orjson-3.10.10-cp39-cp39-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (270 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Installing collected packages: tenacity, pydantic-core, orjson, jsonpatch, annotated-types, requests-toolbelt, pydantic, ollama, langsmith, langchain-core, langchain-ollama\n",
      "Successfully installed annotated-types-0.7.0 jsonpatch-1.33 langchain-core-0.3.12 langchain-ollama-0.2.0 langsmith-0.1.137 ollama-0.3.3 orjson-3.10.10 pydantic-2.9.2 pydantic-core-2.23.4 requests-toolbelt-1.0.0 tenacity-9.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55183ffc-ff22-4014-b1eb-d99f3b9c7a36",
   "metadata": {},
   "source": [
    "### Assign Granite model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deeceaeb-ce23-452a-ab2a-8698abe5ddb1",
   "metadata": {},
   "source": [
    "Assign your choice of Granite Model in the variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2e86c88-4fd6-4bd6-b05d-7d246ef5e5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"granite3-dense:2b\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d8d991-71e0-4d50-bbbc-785ca3e060b6",
   "metadata": {},
   "source": [
    "### Create model instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb034f11-3678-4521-9f45-dfb530b0bc8e",
   "metadata": {},
   "source": [
    " Create OllamaLLM instance with the above selected Granite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78dbb566-f914-461a-b88b-d8da182b87fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "model = OllamaLLM(model=model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a257aa45-da82-4216-95e3-af60eecd0b55",
   "metadata": {},
   "source": [
    "### Invoke the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70a5ece-b799-46b4-aea0-9c6a668fd776",
   "metadata": {},
   "source": [
    "Invoke the model with the given prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2780478f-d179-488b-9e79-d7ecbe9283d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kubernetes, also known as K8s, is an open-source container-orchestration system for automating application deployment, scaling, and management. It was originally developed by Google and is now maintained by the Cloud Native Computing Foundation (CNCF). Kubernetes groups containers into logical units for easy management and discovery. It provides a way to automatically place containers on nodes in a cluster based on resource usage and other factors.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What is Kubernetes\"\n",
    "\n",
    "response = model.invoke(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a7ea89-cf9c-42fb-bdd1-78adc411ff33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
